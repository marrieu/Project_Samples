{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, mean_squared_error, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_boston()\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((506, 13), (506,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33.388062189324316,\n",
       " array([-1.28060398e-01,  3.77955693e-02,  5.86107797e-02,  3.24007007e+00,\n",
       "        -1.62222676e+01,  3.89352244e+00, -1.27879944e-02, -1.42326864e+00,\n",
       "         2.34513082e-01, -8.20261127e-03, -9.29950535e-01,  1.19151410e-02,\n",
       "        -5.48489997e-01]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.intercept_ , lm.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.747143360308847"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((569, 30), (569,))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = LogisticRegression()\n",
    "lm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 63   4]\n",
      " [  4 117]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.94      0.94        67\n",
      "          1       0.97      0.97      0.97       121\n",
      "\n",
      "avg / total       0.96      0.96      0.96       188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9574468085106383"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_SVM = svm.SVC(kernel='linear', C=0.1)\n",
    "model_SVM.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_SVM = model_SVM.predict(X_train)\n",
    "pred_test_SVM = model_SVM.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.97\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "print('Train accuracy: {}'.format(accuracy_score(y_train,pred_train_SVM)))\n",
    "print('Test accuracy: {}'.format(accuracy_score(y_test,pred_test_SVM)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  0 16]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,pred_test_SVM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_RF = RandomForestClassifier(max_depth=3, random_state=0)\n",
    "model_RF.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_RF = model_RF.predict(X_train)\n",
    "pred_test_RF = model_RF.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.95\n",
      "Test accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "print('Train accuracy: {}'.format(accuracy_score(y_train,pred_train_RF)))\n",
    "print('Test accuracy: {}'.format(accuracy_score(y_test,pred_test_RF)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  1 15]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,pred_test_RF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Discrimant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LD = LinearDiscriminantAnalysis()\n",
    "model_LD.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_LD = model_LD.predict(X_train)\n",
    "pred_test_LD = model_LD.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.98\n",
      "Test accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "print('Train accuracy: {}'.format(accuracy_score(y_train,pred_train_LD)))\n",
    "print('Test accuracy: {}'.format(accuracy_score(y_test,pred_test_LD)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  1 15]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,pred_test_LD))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf1 = VotingClassifier(estimators=[('SVM', model_SVM), ('RF', model_RF), ('LD', model_LD)], voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('SVM', SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)), ('RF', RandomForestClassifier(bootstrap=True, clas...None, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=False, tol=0.0001))],\n",
       "         flatten_transform=None, n_jobs=1, voting='hard', weights=None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclf1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariavarga/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/mariavarga/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "pred_train = eclf1.predict(X_train)\n",
    "pred_test = eclf1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.97\n",
      "Test accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "print('Train accuracy: {}'.format(accuracy_score(y_train,pred_train)))\n",
    "print('Test accuracy: {}'.format(accuracy_score(y_test,pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  1 15]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers.core import Activation,Dropout,Dense, Dropout\n",
    "from keras.layers import Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.regularizers import l1,l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "y_r = y.reshape(-1,1)\n",
    "y_onehot = onehot_encoder.fit_transform(y_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_shape=4):\n",
    "    \n",
    "    inputs = Input(shape=(input_shape,))\n",
    "    X = BatchNormalization()(inputs)\n",
    "    #X = Dropout(0.3)(inputs)\n",
    "    X = Dense(100,activation='relu')(X)\n",
    "    #X = Dense(60,activation='relu',activity_regularizer=l1(0.01))(X)\n",
    "    #X = Dropout(0.3)(X)\n",
    "    #X = BatchNormalization()(X)\n",
    "    #X = Dense(20,activation='relu')(X)\n",
    "    #X = Dropout(0.5)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Dense(3,activation='softmax')(X)\n",
    "    model = Model(inputs=inputs, outputs=X)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               500       \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 1,219\n",
      "Trainable params: 1,011\n",
      "Non-trainable params: 208\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.00001)\n",
    "NN.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100 samples, validate on 50 samples\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 0s 205us/step - loss: 0.1177 - acc: 0.9600 - val_loss: 0.1141 - val_acc: 0.9800\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 0s 237us/step - loss: 0.1506 - acc: 0.9300 - val_loss: 0.1134 - val_acc: 0.9800\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 0s 282us/step - loss: 0.1325 - acc: 0.9700 - val_loss: 0.1129 - val_acc: 0.9800\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 0s 230us/step - loss: 0.1327 - acc: 0.9500 - val_loss: 0.1132 - val_acc: 0.9800\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 0s 237us/step - loss: 0.1337 - acc: 0.9500 - val_loss: 0.1128 - val_acc: 0.9800\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 0s 200us/step - loss: 0.1384 - acc: 0.9400 - val_loss: 0.1121 - val_acc: 0.9800\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 0s 213us/step - loss: 0.1169 - acc: 0.9700 - val_loss: 0.1120 - val_acc: 0.9800\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 0s 186us/step - loss: 0.1042 - acc: 0.9700 - val_loss: 0.1121 - val_acc: 0.9800\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 0s 198us/step - loss: 0.1109 - acc: 0.9800 - val_loss: 0.1123 - val_acc: 0.9800\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 0s 208us/step - loss: 0.1147 - acc: 0.9800 - val_loss: 0.1126 - val_acc: 0.9800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a35382810>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.fit(X_train, y_train, epochs=10, validation_data = (X_test, y_test),shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(y)\n",
    "\n",
    "# apply encoding to labels\n",
    "labels = le.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.layers import Input, Add, concatenate, Flatten\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = digits.images\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np_utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#onehot_encoder = OneHotEncoder(sparse=False)\n",
    "#y_r = y.reshape(-1,1)\n",
    "#y = onehot_encoder.fit_transform(y_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.expand_dims(X,-1)\n",
    "X = X/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path ='/Users/mariavarga/Documents/Blue Fairy/Papers/*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = glob.glob(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = glob.glob('*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['face2.png']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_resize(fname, img_sz = (480,360)):\n",
    "    img = cv2.imread(fname)\n",
    "    img = resize(img, img_sz)\n",
    "    return img[:,:,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.stack([open_resize(im) for im in fnames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 480, 360, 3)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_archt(input_shape=(256,256,3)):\n",
    "    \n",
    "    inputs = Input(shape=input_shape)\n",
    "    X = Conv2D(filters=40, kernel_size=3, padding='same', activation='relu')(inputs)\n",
    "    X = MaxPooling2D()(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Conv2D(filters=40, kernel_size=3, padding='same', activation='relu')(X)\n",
    "    X = MaxPooling2D()(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = UpSampling2D()(X)\n",
    "    X = Conv2D(filters=40, kernel_size=3, padding='same', activation='relu')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = UpSampling2D()(X)\n",
    "    X = Conv2D(filters=40, kernel_size=3, padding='same', activation='relu')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Conv2D(filters=10, kernel_size=1, padding='same', activation='softmax')(X)\n",
    "    \n",
    "    model = Model(inputs,X)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_archt(input_shape=(8,8,1)):\n",
    "    \n",
    "    inputs = Input(shape=input_shape)\n",
    "    X = Conv2D(filters=50, kernel_size=3, padding='same', activation='relu')(inputs)\n",
    "    X = MaxPooling2D()(X)\n",
    "    X = Dropout(0.3)(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Conv2D(filters=50, kernel_size=3, padding='same', activation='relu')(X)\n",
    "    X = MaxPooling2D()(X)\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(10, activation= 'softmax')(X)\n",
    "    \n",
    "    model = Model(inputs,X)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_archt(input_shape=(8,8,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 8, 8, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 8, 8, 50)          500       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 4, 4, 50)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 50)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 4, 4, 50)          200       \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 4, 4, 50)          22550     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 2, 2, 50)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 25,260\n",
      "Trainable params: 25,160\n",
      "Non-trainable params: 100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.001)\n",
    "model.compile(opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1203 samples, validate on 594 samples\n",
      "Epoch 1/10\n",
      "1203/1203 [==============================] - 4s 3ms/step - loss: 1.8742 - acc: 0.4904 - val_loss: 1.0768 - val_acc: 0.8350\n",
      "Epoch 2/10\n",
      "1203/1203 [==============================] - 3s 2ms/step - loss: 0.7353 - acc: 0.8229 - val_loss: 0.3972 - val_acc: 0.8923\n",
      "Epoch 3/10\n",
      "1203/1203 [==============================] - 3s 2ms/step - loss: 0.3549 - acc: 0.9027 - val_loss: 0.2097 - val_acc: 0.9377\n",
      "Epoch 4/10\n",
      "1203/1203 [==============================] - 3s 3ms/step - loss: 0.2256 - acc: 0.9377 - val_loss: 0.1505 - val_acc: 0.9562\n",
      "Epoch 5/10\n",
      "1203/1203 [==============================] - 3s 3ms/step - loss: 0.1650 - acc: 0.9501 - val_loss: 0.1478 - val_acc: 0.9495\n",
      "Epoch 6/10\n",
      "1203/1203 [==============================] - 3s 3ms/step - loss: 0.1498 - acc: 0.9609 - val_loss: 0.0946 - val_acc: 0.9747\n",
      "Epoch 7/10\n",
      "1203/1203 [==============================] - 3s 3ms/step - loss: 0.1039 - acc: 0.9726 - val_loss: 0.0726 - val_acc: 0.9832\n",
      "Epoch 8/10\n",
      "1203/1203 [==============================] - 3s 2ms/step - loss: 0.0907 - acc: 0.9742 - val_loss: 0.0912 - val_acc: 0.9714\n",
      "Epoch 9/10\n",
      "1203/1203 [==============================] - 3s 2ms/step - loss: 0.0738 - acc: 0.9859 - val_loss: 0.0664 - val_acc: 0.9848\n",
      "Epoch 10/10\n",
      "1203/1203 [==============================] - 3s 2ms/step - loss: 0.0749 - acc: 0.9834 - val_loss: 0.0582 - val_acc: 0.9832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c42d32f90>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=16, epochs=10, validation_data=[X_test,y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "594/594 [==============================] - 0s 641us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05817211266318555, 0.9831649833656722]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('lalala.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
